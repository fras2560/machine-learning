---------------------------------------------------------------
Week - 9
---------------------------------------------------------------
Problem Motivation
---------------------------------------------------------------

	Anonmaly Detection
		-> want to know if new engine should under go more testing
		-> Given a new exmaple see if it is not normal and try more testing

	Density Estimation
		-> Fraud Detection
		check p(x) < Epsilon

	Question:
		Your anomaly detection system flags x as anomalous whenever p(x) <= epsilon. Suppose your system is flagging too many things as anomalous that are not actually so. What should you do?
			Try decreasing epsilon

---------------------------------------------------------------
Gaussian Distribution
---------------------------------------------------------------
	Also known as a normal distribution

	As sigma grows it becomes flatter, as sigma shrinks becomes tighter

		Question
			The formula for the Gaussian density is:
			p(x) = 1/sqrt(2 pi sigma) exp(- [x - u]^2 / [2 sigma^2])
			u = -3
			sigma = 2

			p(x) = 1/sqrt(2 pi 2) exp(- [x + 3]^2 / [2 * 4])

---------------------------------------------------------------
Algorithm
---------------------------------------------------------------

	Question
		Given a training set {X1, ..., xm}, how would you estimate each uj and sigma_j^2
		uj = 1/m sum i=1, m(xj)
		sigma_j^2 = 1/m sum i=1, m(xj -uj)^2

---------------------------------------------------------------
Developing and Evaluating an Anomaly Detection System
---------------------------------------------------------------

	Question:
		Suppose you have fit a model p(x). When evaluating on the cross validation set of test, your algorithm predicts:
		y = {
				1 if p(x)<= epsilon
				0 if p(x) > epsilon
		}
		Is classification accuracy a goow way to measure the algorithm's performance?

		No, because of skewed classes (so an algorithm that always predicts u = 0 will have high accuracy)

	Possible eval metrics
		- tp, fp, fn, tn
		- precision/recall
		- f1-score
		- cross validation set to choose epsilon

---------------------------------------------------------------
Anomaly Detection vs. Supervised Learning
---------------------------------------------------------------
	anomaly better for small number of positive examples
	anomalies are all very differnt and current examples may not look like future anomalies
	This is different than supervised learning

		Question
			Which of the following problems would you approach with an anomaly detection algorithm?
				-> You run a power utility and want to monitor your electric plants to see if any one of them might be behaving strangely
				-> A computer vision/ security application , where you examine video images to see if anyone in your company's parking lot is acting in an unusual way.

---------------------------------------------------------------
Choosing What Features to Use
---------------------------------------------------------------
	if distribution is left tailed skewed can use a log to convert to normal distribution
	sqrt -> another transformation
	x^1/k -> another way to play with the data

	Want p(x) large for normal exmaples
		p(x) small for anomalous examples

	Question
		Suppose your anomaly detection algo is performing poorly and outputs a large value of p(x) for many normal examples and for many anomalous exmaples in your cross validation dataset. Which of the following changes to your algo is most likely to help?

			-> Try coming up with more features to distinguish between the normal and the anomalous examples


Quiz
1.
	For which of the following problems would anomaly detection be a suitable algorithm?

		-> In a computer chip fabrication plant, identify microchips that might be defective.

		Given data from credit card transactions, classify each transaction according to type of purchase (for example: food, transportation, clothing).

		From a large set of hospital patient records, predict which patients have a particular disease (say, the flu).

		-> From a large set of primary care patient records, identify individuals who might have unusual health conditions.
2.
	 Suppose you have trained an anomaly detection system that flags anomalies when p(x) is less than ε, and you find on the cross-validation set that it has too many false positives (flagging too many things as anomalies). What should you do?

		Increase ε

		-> Decrease ε
3.
	 Suppose you are developing an anomaly detection system to catch manufacturing defects in airplane engines. You model uses
	p(x)=∏j=1np(xj;μj,σj2).
	You have two features x1 = vibration intensity, and x2 = heat generated. Both x1 and x2 take on values between 0 and 1 (and are strictly greater than 0), and for most "normal" engines you expect that x1≈x2. One of the suspected anomalies is that a flawed engine may vibrate very intensely even without generating much heat (large x1, small x2), even though the particular values of x1 and x2 may not fall outside their typical ranges of values. What additional feature x3 should you create to capture these types of anomalies:

		x3=x1+x2

		x3=x12×x2

		->x3=x1/x2

		x3=x1×x2

4.
	Which of the following are true? Check all that apply.

		->When choosing features for an anomaly detection system, it is a good idea to look for features that take on unusually large or small values for (mainly the) anomalous examples.

		If you are developing an anomaly detection system, there is no way to make use of labeled data to improve your system.

		If you have a large labeled training set with many positive examples and many negative examples, the anomaly detection algorithm will likely perform just as well as a supervised learning algorithm such as an SVM.

		->If you do not have any labeled data (or if all your data has label y=0), then is is still possible to learn p(x), but it may be harder to evaluate the system or choose a good value of ϵ.

5.
	 You have a 1-D dataset {x(1),…,x(m)} and you want to detect outliers in the dataset. You first plot the dataset and it looks like this:
	Suppose you fit the gaussian distribution parameters μ1 and σ12 to this dataset. Which of the following values for μ1 and σ12 might you get?

		->μ1=−3,σ12=4

		μ1=−6,σ12=4

		μ1=−3,σ12=2

		μ1=−6,σ12=2

---------------------------------------------------------------
Problem Formulation
---------------------------------------------------------------
n_u = number of users
n_m = number of movies
r(i,j) = 1 if user j jas rated movie i
y(i,j) = rating given by user j to movie i

---------------------------------------------------------------
Content Based Recommendations
---------------------------------------------------------------
Question

	Movie 	Alice 	Bob	Carol	David	Romance	Action
	love	5		5	0		0		0.9		0
	Romance	5		?	?		0		1.0		0.01
	Cute 	?		4	0		?		0.99	0
	Chase 	0		0	5		4		0.1		1.0
	Swords	0		0	5		?		0		0.9

	Which of the following is a reasonable value for theta^3? Recall that x_0 = 1
	theta^3 = [0;0;5]

How to learn theta_j
	=min theta_j by sum(i:r[i,j]=1) (transpose(theta^j)(X_i) - y^(i,j))^2 + lambda / (2*m^j) sum(k=1, n) (theta_k^j)^2

---------------------------------------------------------------
Collaborative Filtering
---------------------------------------------------------------
An algo that starts to learn by itself what features to use

Question:
	Suppose you use gradient descent to minimize:
		Gradient descent update rule
		Whihc of the following is a correct gradient descent update rule for i!=0
		x_k^i = x_k^i - alpha(sum (j:r(i,j)=1))(transpose(theta^j) x^i - y^(i,j) theta_k^j + lambda x_k^i)

---------------------------------------------------------------
Collaborative Filtering Algorithm
---------------------------------------------------------------
	Question
		In the algo we described, we initialized x1,...,xn_m and theta_1,... theta(n_u) to small random values. Why is this?

		This serves as symmetry breaking and ensures the algo learns features x1,... xnm that are different from each other

---------------------------------------------------------------
Low Rank Matrix Factorization
---------------------------------------------------------------
	Question:
		What is another way of writing the following:
		[
		x1^Ttheta1 ... x1^Ttheta_nu
		...
		xnm^Ttheta1 ... xnm^Ttheta_nu
		]
		Xtheta^T

How to find movies j related to movie i
	small ||x_i - x_j|| -> similar

---------------------------------------------------------------
Implementational Detail: Mean Normalization
---------------------------------------------------------------
What to do when Users have no ratings?
	-> defaults to zero
	u = average ratings of all the movies
	now adjust y - u
	each movie has an average rating of zero
	For users no predict theta_j^T xi + u_i
	Pretty much default is the average rating

Question:
	We talked about mean normalization. However, unlike some other applications of feature scaling, we did not scale the movie ratings by dividing by the range (max - min value). This is because:

	All the movie ratings are already comparable (eg 0 to 5) so they are already on similar scales


Quiz
1. X
 Suppose you run a bookstore, and have ratings (1 to 5 stars)
of books. Your collaborative filtering algorithm has learned
a parameter vector θ(j) for user j, and a feature
vector x(i) for each book. You would like to compute the
"training error", meaning the average squared error of your
system's predictions on all the ratings that you have gotten
from your users. Which of these are correct ways of doing so (check all that apply)?
For this problem, let m be the total number of ratings you
have gotten from your users. (Another way of saying this is
that m=∑i=1nm∑j=1nur(i,j)). [Hint: Two of the four options below are correct.]

1m∑j=1nu∑i:r(i,j)=1(∑k=1n(θ(k))jxi(k)−y(i,j))2

->1m∑(i,j):r(i,j)=1((θ(j))Tx(i)−r(i,j))2

1m∑i=1nm∑j:r(i,j)=1(∑k=1n(θ(j))kxk(i)−y(i,j))2

1m∑(i,j):r(i,j)=1((θ(j))Tx(i)−y(i,j))2

2.
	 In which of the following situations will a collaborative filtering system be the most appropriate learning algorithm (compared to linear or logistic regression)?

		->You own a clothing store that sells many styles and brands of jeans. You have collected reviews of the different styles and brands from frequent shoppers, and you want to use these reviews to offer those shoppers discounts on the jeans you think they are most likely to purchase

		You manage an online bookstore and you have the book ratings from many users. You want to learn to predict the expected sales volume (number of books sold) as a function of the average rating of a book.

		->You run an online bookstore and collect the ratings of many users. You want to use this to identify what books are "similar" to each other (i.e., if one user likes a certain book, what are other books that she might also like?)

		You're an artist and hand-paint portraits for your clients. Each client gets a different portrait (of themselves) and gives you 1-5 star rating feedback, and each client purchases at most 1 portrait. You'd like to predict what rating your next customer will give you.

3.
	 You run a movie empire, and want to build a movie recommendation system based on collaborative filtering. There were three popular review websites (which we'll call A, B and C) which users to go to rate movies, and you have just acquired all three companies that run these websites. You'd like to merge the three companies' datasets together to build a single/unified system. On website A, users rank a movie as having 1 through 5 stars. On website B, users rank on a scale of 1 - 10, and decimal values (e.g., 7.5) are allowed. On website C, the ratings are from 1 to 100. You also have enough information to identify users/movies on one website with users/movies on a different website. Which of the following statements is true?

		->You can merge the three datasets into one, but you should first normalize each dataset's ratings (say rescale each dataset's ratings to a 0-1 range).

		It is not possible to combine these websites' data. You must build three separate recommendation systems.

		Assuming that there is at least one movie/user in one database that doesn't also appear in a second database, there is no sound way to merge the datasets, because of the missing data.

		You can combine all three training sets into one as long as your perform mean normalization and feature scaling after you merge the data.

4. X
	Which of the following are true of collaborative filtering systems? Check all that apply.

		Suppose you are writing a recommender system to predict a user's book preferences. In order to build such a system, you need that user to rate all the other books in your training set.

		->Even if each user has rated only a small fraction of all of your products (so r(i,j)=0 for the vast majority of (i,j) pairs), you can still build a recommender system by using collaborative filtering.

		For collaborative filtering, it is possible to use one of the advanced optimization algoirthms (L-BFGS/conjugate gradient/etc.) to solve for both the x(i)'s and θ(j)'s simultaneously.

		->For collaborative filtering, the optimization algorithm you should use is gradient descent. In particular, you cannot use more advanced optimization algorithms (L-BFGS/conjugate gradient/etc.) for collaborative filtering, since you have to solve for both the x(i)'s and θ(j)'s simultaneously.

5. X
	Suppose you have two matrices A and B, where A is 5x3 and B is 3x5. Their product is C=AB, a 5x5 matrix. Furthermore, you have a 5x5 matrix R where every entry is 0 or 1. You want to find the sum of all elements C(i,j) for which the corresponding R(i,j) is 1, and ignore all elements C(i,j) where R(i,j)=0. One way to do so is the following code:
	Which of the following pieces of Octave code will also correctly compute this total? Check all that apply. Assume all options are in code.

		total = sum(sum((A * B) .* R))

		C = A * B; total = sum(sum(C(R == 1)));

		->C = (A * B) * R; total = sum(C(:));

		->total = sum(sum(A(R == 1) * B(R == 1));


1. X
 Suppose you run a bookstore, and have ratings (1 to 5 stars)
of books. Your collaborative filtering algorithm has learned
a parameter vector θ(j) for user j, and a feature
vector x(i) for each book. You would like to compute the
"training error", meaning the average squared error of your
system's predictions on all the ratings that you have gotten
from your users. Which of these are correct ways of doing so (check all that apply)?
For this problem, let m be the total number of ratings you
have gotten from your users. (Another way of saying this is
that m=∑i=1nm∑j=1nur(i,j)). [Hint: Two of the four options below are correct.]

m∑(i,j):r(i,j)=1((θ(j))Tx(i)−r(i,j))2

->1m∑i=1nm∑j:r(i,j)=1(∑k=1n(θ(j))kxk(i)−y(i,j))2

->1m∑j=1nu∑i:r(i,j)=1(∑k=1n(θ(k))jxi(k)−y(i,j))2

1m∑(i,j):r(i,j)=1((θ(j))Tx(i)−y(i,j))2

2.
	 In which of the following situations will a collaborative filtering system be the most appropriate learning algorithm (compared to linear or logistic regression)?

		->You own a clothing store that sells many styles and brands of jeans. You have collected reviews of the different styles and brands from frequent shoppers, and you want to use these reviews to offer those shoppers discounts on the jeans you think they are most likely to purchase

		You manage an online bookstore and you have the book ratings from many users. You want to learn to predict the expected sales volume (number of books sold) as a function of the average rating of a book.

		->You run an online bookstore and collect the ratings of many users. You want to use this to identify what books are "similar" to each other (i.e., if one user likes a certain book, what are other books that she might also like?)

		You're an artist and hand-paint portraits for your clients. Each client gets a different portrait (of themselves) and gives you 1-5 star rating feedback, and each client purchases at most 1 portrait. You'd like to predict what rating your next customer will give you.

3.
	 You run a movie empire, and want to build a movie recommendation system based on collaborative filtering. There were three popular review websites (which we'll call A, B and C) which users to go to rate movies, and you have just acquired all three companies that run these websites. You'd like to merge the three companies' datasets together to build a single/unified system. On website A, users rank a movie as having 1 through 5 stars. On website B, users rank on a scale of 1 - 10, and decimal values (e.g., 7.5) are allowed. On website C, the ratings are from 1 to 100. You also have enough information to identify users/movies on one website with users/movies on a different website. Which of the following statements is true?

		->You can merge the three datasets into one, but you should first normalize each dataset's ratings (say rescale each dataset's ratings to a 0-1 range).

		It is not possible to combine these websites' data. You must build three separate recommendation systems.

		Assuming that there is at least one movie/user in one database that doesn't also appear in a second database, there is no sound way to merge the datasets, because of the missing data.

		You can combine all three training sets into one as long as your perform mean normalization and feature scaling after you merge the data.

4. X
	Which of the following are true of collaborative filtering systems? Check all that apply.

		To use collaborative filtering, you need to manually design a feature vector for every item (e.g., movie) in your dataset, that describes that item's most important properties.

		When using gradient descent to train a collaborative filtering system, it is okay to initialize all the parameters (x(i) and θ(j)) to zero.

		->If you have a dataset of users ratings' on some products, you can use these to predict one user's preferences on products he has not rated.

		->Recall that the cost function for the content-based recommendation system is J(θ)=12∑j=1nu∑i:r(i,j)=1(θ(j))Tx(i)−y(i,j)2+λ2∑j=1nu∑k=1n(θk(j))2. Suppose there is only one user and he has rated every movie in the training set. This implies that nu=1 and r(i,j)=1 for every i,j. In this case, the cost function J(θ) is equivalent to the one used for regularized linear regression.

5. X
	Suppose you have two matrices A and B, where A is 5x3 and B is 3x5. Their product is C=AB, a 5x5 matrix. Furthermore, you have a 5x5 matrix R where every entry is 0 or 1. You want to find the sum of all elements C(i,j) for which the corresponding R(i,j) is 1, and ignore all elements C(i,j) where R(i,j)=0. One way to do so is the following code:
	Which of the following pieces of Octave code will also correctly compute this total? Check all that apply. Assume all options are in code.

		->total = sum(sum((A * B) .* R))

		->C = A * B; total = sum(sum(C(R == 1)));

		C = (A * B) * R; total = sum(C(:));

		total = sum(sum(A(R == 1) * B(R == 1));